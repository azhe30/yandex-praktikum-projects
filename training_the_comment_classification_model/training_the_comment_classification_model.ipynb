{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект Обучение модели классификации комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import cv, Pool\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') #скроем предупреждения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение файла `toxic_comments.csv` и сохранение в переменной `df`\n",
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11411</th>\n",
       "      <td>I was advised to return here to inform you of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68818</th>\n",
       "      <td>But what with banning me from Evertype talk? I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157177</th>\n",
       "      <td>\"\\n\\nUsing \"\"bank robber\"\" instead of \"\"crimin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69568</th>\n",
       "      <td>\"==Riddle me this==\\nAnswer me something? You ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145463</th>\n",
       "      <td>Rex, you are really a funny guy... ( )</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81854</th>\n",
       "      <td>June 2009 \\n Please stop your disruptive editi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111716</th>\n",
       "      <td>Urgent complain - Wikipedia \\n\\nAnswer given b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128647</th>\n",
       "      <td>\"\\n\\nI have a more serious problem with this l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21070</th>\n",
       "      <td>I removed the barnstar you had given me \\n\\nI ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135993</th>\n",
       "      <td>\":No problem at all, thanks for clarifying for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "11411   I was advised to return here to inform you of ...      0\n",
       "68818   But what with banning me from Evertype talk? I...      0\n",
       "157177  \"\\n\\nUsing \"\"bank robber\"\" instead of \"\"crimin...      0\n",
       "69568   \"==Riddle me this==\\nAnswer me something? You ...      0\n",
       "145463             Rex, you are really a funny guy... ( )      0\n",
       "81854   June 2009 \\n Please stop your disruptive editi...      0\n",
       "111716  Urgent complain - Wikipedia \\n\\nAnswer given b...      0\n",
       "128647  \"\\n\\nI have a more serious problem with this l...      0\n",
       "21070   I removed the barnstar you had given me \\n\\nI ...      0\n",
       "135993  \":No problem at all, thanks for clarifying for...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# просмотр 10 случайных строк таблицы `df`\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#получение общей информации о таблице `df`\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице 2 столбца. Типы данных в столбцах: object и int64.\n",
    "\n",
    "Согласно документации к данным:\n",
    "* `text` — содержит текст комментария;\n",
    "* `toxic` — отметка о токсичности комментариев пользователей: 1 - токсичный комментарий, 0 - нетоксичный.\n",
    "\n",
    "Целевой признак - `toxic`.\n",
    "\n",
    "Названия столбцов соответствуют хорошему стилю.\n",
    "\n",
    "Количество значений в столбцах одинаковое, значит, пропущенных значений нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждой строке таблицы содержится текст комментариев пользователей с отметкой об их токсичности. \n",
    "\n",
    "Предварительно можно утверждать, что, данных достаточно для выбора модели. Пропусков в данных не обнаружено, название столбца соответствует хорошему стилю.\n",
    "\n",
    "Чтобы двигаться дальше, нужно подготовить данные для построения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш целевой признак `toxic` (отметка о токсичности комментариев) - является категориальным, поэтому мы будем подбирать модель для решения задачи классификации. Так как в нашем случае признака всего два (токсичный комментарий или нет), то нас интересует бинарная классификация.\n",
    "\n",
    "Используем модели Логистическая регрессия и CatBoostClassifier. Для кодирования текстов в векторный вид используем нейронную сеть BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка баланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные на сбалансированность классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = df['toxic'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в таблице не сбалансированы, токсичиных комментариев намного меньше. Попробуем обучить модели на несбалансированных данных. Объём датасета достаточно большой - отберём из датасета 800 строк для обучающей выборки и 200 строк - для тестовой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.sample(800).reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# баланс классов в обучающей выборке\n",
    "train['toxic'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.sample(200).reset_index(drop=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# баланс классов в тестовой выборке\n",
    "test['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем токенизатор как объект класса BertTokenizer(), передадим ему файл со словарём, на котором обучалась модель\n",
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file='/Users/evgeniaabaseva/Documents/Study/Yandex/12.Машинное-обучение-для-текстов/toxic-bert/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/evgeniaabaseva/Documents/Study/Yandex/12.Машинное-обучение-для-текстов/toxic-bert/pytorch_model.bin were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель класса BertModel, передадим ей файл с предобученной моделью и конфигурацией\n",
    "config = transformers.BertConfig.from_json_file(\n",
    "    '/Users/evgeniaabaseva/Documents/Study/Yandex/12.Машинное-обучение-для-текстов/toxic-bert/config.json')\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    '/Users/evgeniaabaseva/Documents/Study/Yandex/12.Машинное-обучение-для-текстов/toxic-bert/pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим эмбеддинги BERT для обучающей выборки, установим max_length=512 для того чтобы учесть ограничение BERT на количество слов = 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 800/800 [00:03<00:00, 262.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# преобразуем текст в номера токенов из словаря методом encode()\n",
    "tokenized = train['text'].progress_apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512, padding=\"max_length\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим максимальную длину вектора в полученной таблице\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь поясним модели, что нули не несут значимой информации, «создадим маску» - укажем нулевые и не нулевые значения\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af74ed92e649b0911e4ed0edcbba64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# зададим размер батча\n",
    "batch_size = 100\n",
    "\n",
    "# сделаем пустой список для хранения эмбеддингов твитов\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        # преобразуем данные в формат тензоров в библиотеке torch\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        # преобразуем маску\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        # укажем, что градиенты не нужны\n",
    "        with torch.no_grad():\n",
    "            # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        # из полученного тензора извлечём нужные элементы и добавим в список всех эмбеддингов\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соберём все эмбеддинги в матрицу признаков\n",
    "features_train = np.concatenate(embeddings)\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим эмбеддинги BERT для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 200/200 [00:01<00:00, 173.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# преобразуем текст в номера токенов из словаря методом encode()\n",
    "tokenized_test = test['text'].progress_apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512, padding=\"max_length\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим максимальную длину вектора в полученной таблице\n",
    "max_len = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными\n",
    "padded_test = np.array([i + [0]*(max_len - len(i)) for i in tokenized_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь поясним модели, что нули не несут значимой информации, «создадим маску» - укажем нулевые и не нулевые значения\n",
    "attention_mask_test = np.where(padded_test != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c241c10788be47cf926645b419de5129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# зададим размер батча\n",
    "batch_size = 50\n",
    "\n",
    "# сделаем пустой список для хранения эмбеддингов твитов\n",
    "embeddings_test = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded_test.shape[0] // batch_size)):\n",
    "        # преобразуем данные в формат тензоров в библиотеке torch\n",
    "        batch = torch.LongTensor(padded_test[batch_size*i:batch_size*(i+1)]) \n",
    "        # преобразуем маску\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask_test[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        # укажем, что градиенты не нужны\n",
    "        with torch.no_grad():\n",
    "            # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        # из полученного тензора извлечём нужные элементы и добавим в список всех эмбеддингов\n",
    "        embeddings_test.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соберём все эмбеддинги в матрицу признаков\n",
    "features_test = np.concatenate(embeddings_test)\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "На данном этапе мы:\n",
    "1. проверили данные на сбалансированность классов - классы не сбалансированы, для того чтобы сбалансировать классы мы ограничили размер выборки до 2тыс, выбрав случайно по 1000 строк каждого класса, а также сформировали тестовую выборку с учётом дисбаланса классов;\n",
    "2. создали эмбеддинги для обучающей и тестовой выборок при помощи нейронной сети BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка выборок для обучения и тестирования моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши таблицы на обучающую и тестовую выборки в соотношении 4:1 - 80% обучающая выборка и 20% тестовая выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 768)\n",
      "(200, 768)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# сохраним таргеты в отдельные переменные\n",
    "target_train = train['toxic']\n",
    "target_test = test['toxic']\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе мы проверили даные на баланс классов - данные в таблице не сбалансированы, приняли решение обучать и тестировать модель на несбалансированных данных; а также подготовили признаки для обучающей и тестовой выборок, применив нейронную сеть BERT для кодирования текстов в векторный вид, и таргеты соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём значения гиперпараметров для модели Логистическая регрессия, обучим её и оценитм качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parametres: {'C': 0.1, 'class_weight': 'None', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "F1: 0.9318859167416044\n",
      "CPU times: user 35.1 s, sys: 3.18 s, total: 38.3 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "parametrs = {\n",
    "    'class_weight': ['balanced', 'None'],\n",
    "    'penalty' : ['l1','l2'], \n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(logreg, parametrs, scoring='f1', cv=5, n_jobs = 1, verbose = 0, return_train_score=True)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "print('Best parametres:', clf.best_params_)\n",
    "print('F1:', clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения гиперпараметров Логистической регрессии для лучшего значения F1 на обучающей выборке: C = 0.1, class_weight = None, penalty = l2, solver = newton-cg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающей выборке: 0.9714285714285714\n",
      "F1 на тестовой выборке: 0.9767441860465117\n",
      "CPU times: user 174 ms, sys: 16.9 ms, total: 191 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(C=0.1, class_weight='None', penalty='l2', solver='newton-cg')\n",
    "model.fit(features_train, target_train) # обучим модель на тренировочной выборке\n",
    "\n",
    "# получим предсказания модели на обучающей выборке и посчитаем значение метрики F1 \n",
    "pred_train = model.predict(features_train)\n",
    "f1_train = f1_score(target_train, pred_train)\n",
    "\n",
    "# получим предсказания модели на тестовой выборке и посчитаем значение метрики F1 \n",
    "pred_test = model.predict(features_test)\n",
    "f1_test = f1_score(target_test, pred_test)\n",
    "\n",
    "print('F1 на обучающей выборке:', f1_train)\n",
    "print('F1 на тестовой выборке:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "F1 на обучающей выборке 0.97, на тестовой - 0.97, что удовлетворяет условию задачи (значение метрики F1 должно быть не меньше 0.75), время работы модели = 131 ms. Модель не переобучилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём значения гиперпараметров для модели CatBoostClassifier, обучим её и оценитм качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = CatBoostClassifier()\n",
    "\n",
    "grid = {'learning_rate': [0.01, 0.5],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_search_result = model.grid_search(grid, \n",
    "                                       X=features_train, \n",
    "                                       y=target_train,\n",
    "                                       cv=3,\n",
    "                                       plot=True)\n",
    "\n",
    "print('Best parametres:', clf.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём объект для catboost, на котором будем обучать модель\n",
    "train_data = Pool(data=features_train, label=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём объект для catboost, на котором будем тестировать модель\n",
    "test_data = Pool(data=features_test, label=target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры для модели\n",
    "params = {'eval_metric': 'F1',\n",
    "          'loss_function': 'Logloss',\n",
    "          'random_seed': 42,\n",
    "          'learning_rate': 0.5,\n",
    "          'depth': 6,\n",
    "          'l2_leaf_reg': 3,\n",
    "          'verbose':100,\n",
    "          'early_stopping_rounds':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9132948\ttotal: 386ms\tremaining: 6m 25s\n",
      "100:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 2m 7s\n",
      "200:\tlearn: 1.0000000\ttotal: 28.1s\tremaining: 1m 51s\n",
      "300:\tlearn: 1.0000000\ttotal: 45.4s\tremaining: 1m 45s\n",
      "400:\tlearn: 1.0000000\ttotal: 57.8s\tremaining: 1m 26s\n",
      "500:\tlearn: 1.0000000\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "600:\tlearn: 1.0000000\ttotal: 1m 22s\tremaining: 54.9s\n",
      "700:\tlearn: 1.0000000\ttotal: 1m 34s\tremaining: 40.3s\n",
      "800:\tlearn: 1.0000000\ttotal: 1m 46s\tremaining: 26.4s\n",
      "900:\tlearn: 1.0000000\ttotal: 1m 58s\tremaining: 13s\n",
      "999:\tlearn: 1.0000000\ttotal: 2m 10s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fecb8b3ffd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(test_data)\n",
    "f1_test = f1_score(target_test, pred_test)\n",
    "f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "F1 на обучающей выборке 1, на тестовой - 0.95, что удовлетворяет условию задачи (значение метрики F1 должно быть не меньше 0.75), время работы модели = 6m 25s. Модель переобучилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе мы подобрали значения ниперпараметров для моделей LogisticRegression и CatBoostClassifier, обучили их и получили предсказания по обучающей и тестовой выборкам, а также рассчитали значение метрики F1 на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим таблицу сравнения полученных метрик и времени работы моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>131 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>6min 25s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  F1_train  F1_test      time\n",
       "0  LogisticRegression      0.97     0.97    131 ms\n",
       "1  CatBoostClassifier      1.00     0.95  6min 25s"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.DataFrame({'model': ['LogisticRegression', 'CatBoostClassifier'], \n",
    "                      'F1_train': [0.97, 1],\n",
    "                      'F1_test': [0.97, 0.95],\n",
    "                      'time': ['131 ms', '6min 25s']})\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Значение метрики F1 на тестовой выборке больше 0.75 у обеих моделей, при этом модель CatBoostClassifier переобучается и отрабатывает гораздо больше времени, чем LogisticRegression. Исходя из полученных результатов предлагается выбрать модель LogisticRegression, значение F1 на тестовой выборке = 0.97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследование проводилось в четыре этапа:\n",
    "\n",
    "* На этапе Обзор данных мы ознакомились с данными в предоставленной таблице и зафиксировали, что предварительно данных для проведения исследования достаточно;\n",
    "* На этапе Подготовка данных мы проверили даные на баланс классов, подготовили признаки для обучающей и тестовой выборок, применив нейронную сеть BERT для кодирования текстов в векторный вид, и таргеты соответственно;\n",
    "* На этапе Обучение разных моделей мы подобрали значения ниперпараметров для моделей LogisticRegression и CatBoostClassifier, обучили их, получили предсказания по обучающей и тестовой выборкам и рассчитали значение метрики F1 для каждой из выборок;\n",
    "* На этапе Выводы мы сформировали итоговую таблицу со значениями метрики F1 на обучающей и тестовой выборках и временем работы моделей, значение метрики F1 на тестовой выборке удовлетворяет условиям проекта у обеих моделей, при этом модель CatBoostClassifier переобучается и отрабатывает гораздо больше времени, чем LogisticRegression.\n",
    "\n",
    "Исходя из полученных результатов для решения задачи классификации комментариев пользователей на позитивные и негативные интернет-магазина «Викишоп» предлагается выбрать модель LogisticRegression, так как значение F1 на тестовой выборке удовлетворяет условиям проекта (=0.97), при этом для решения данной задачи предлагается не производить балансировку классов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
